{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc = pd.read_csv (r'./Accident15.csv')\n",
    "veh = pd.read_csv (r'./Vehicle15.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(veh, acc, how='left', on=['Accident_Index', 'Accident_Index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1.shape\n",
    "#df1.head()\n",
    "list(df)\n",
    "#df.ACC_VEH_ID.nunique()\n",
    "#df.Accident_Index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "#df.head()\n",
    "#df.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data Cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace 'Unknown' and 'null' with nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace('null', np.nan).copy()  #replace null with nan\n",
    "df= df.replace('Unknown', np.nan).copy()\n",
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove nan values from data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete observations with nan values\n",
    "\n",
    "#df.apply(pd.Series.nunique)    #number of distinct values\n",
    "\n",
    "df = df.loc[df['Vehicle_Type'].notnull()]\n",
    "df = df.loc[df['Sex_of_Driver'].notnull()]\n",
    "df = df.loc[df['Age_of_Driver'].notnull()]\n",
    "df = df.loc[df['Engine_Capacity'].notnull()]\n",
    "df = df.loc[df['Age_of_Vehicle'].notnull()]\n",
    "df = df.loc[df['Time'].notnull()]\n",
    "df = df.loc[df['Road_Type'].notnull()]\n",
    "df = df.loc[df['Weather_Conditions'].notnull()]\n",
    "df = df.loc[df['Road_Surface_Conditions'].notnull()]\n",
    "df = df.loc[df['Towing_Ind'].notnull()]\n",
    "df = df.loc[df['Vehicle_Manoeuvre'].notnull()]\n",
    "df = df.loc[df['Skidding_and_Overturning'].notnull()]\n",
    "df = df.loc[df['Point_of_Impact'].notnull()]\n",
    "\n",
    "df.isnull().sum()              #number of nan values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Target Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create Target\n",
    "df.is_copy = False\n",
    "df['Target_ind'] = (df.Accident_Severity.isin (['Fatal' , 'Serious'])).astype(int)\n",
    "#df['Target_ind'] = (df.Accident_Severity.isin (['Fatal'])).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Distributions\n",
    "columns =[\n",
    "         'Vehicle_Type',\n",
    "         'Sex_of_Driver',\n",
    "         #'Age_of_Driver',   too many distinct values\n",
    "         #'Engine_Capacity', too many distinct values\n",
    "         #'Age_of_Vehicle',  too many distinct values\n",
    "         'Towing_Ind',\n",
    "         'Vehicle_Manoeuvre',\n",
    "         'Skidding_and_Overturning',\n",
    "         'Point_of_Impact',\n",
    "         'Accident_Severity',\n",
    "         #'Date',            too many distinct values\n",
    "         'Month',\n",
    "         'Day_of_Week',\n",
    "         'Weekend_Ind',\n",
    "         #'Time',            too many distinct values\n",
    "         'Road_Type',\n",
    "         'Speed_limit',\n",
    "         'Light_Conditions',\n",
    "         'Weather_Conditions',\n",
    "         'Road_Surface_Conditions',\n",
    "         'Urban_or_Rural'   ] #columns to graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequency Charts\n",
    "for i in range(len(columns)):\n",
    "\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    df[columns[i]].value_counts().plot(ax=ax, kind='bar',title=columns[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100% Stacked Bar Chart: Target vs Non Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#100% stacked compare Target vs Non Target\n",
    "for i in range(len(columns)):\n",
    "\n",
    "    \n",
    "    compare= pd.crosstab(df[columns[i]], df.Target_ind.astype(bool))\n",
    "    compare.div(compare.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True, color=[\"red\",\"green\"])\n",
    "\n",
    "plt.xticks(rotation='vertical')\n",
    "\n",
    "for i in range(len(columns)):plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert strings to numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert time to minutes since 00:00 to make it easier to use\n",
    "time = pd.DatetimeIndex(df['Time'])\n",
    "df['Minutes_since_midnight'] = (time.hour * 60 + time.minute).astype(int)\n",
    "\n",
    "#convert strings to numerics\n",
    "df['Driver_Age'] = (df.Age_of_Driver).astype(int)\n",
    "df['Vehicle_Age'] = (df.Age_of_Vehicle).astype(int)\n",
    "df['Engine_Capacity'] = (df.Engine_Capacity).astype(int)\n",
    "df['Speed_Limit'] = (df.Speed_limit).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplots for numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vehicle age boxplot\n",
    "df.boxplot(column='Vehicle_Age', by='Target_ind')\n",
    "#Driver age boxplot\n",
    "df.boxplot(column='Driver_Age', by='Target_ind')\n",
    "#Engine capacity boxplot\n",
    "df.boxplot(column='Engine_Capacity', by='Target_ind')\n",
    "#Engine capacity boxplot\n",
    "df.boxplot(column='Minutes_since_midnight', by='Target_ind')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.percentile(df['Engine_Capacity'] ,80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use to list values for new indicators\n",
    "df.Skidding_and_Overturning.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create New Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create indicators for categoricals\n",
    "#Driver Gender\n",
    "df['Male_ind'] = (df.Sex_of_Driver.isin (['Male'])).astype(int)\n",
    "#Urban vs Rural\n",
    "df['Urban_ind'] = (df.Urban_or_Rural.isin (['Urban'])).astype(int)\n",
    "#Weather Conditions\n",
    "df['Fine_Weather_ind'] = (df.Weather_Conditions.isin (['Fine no high winds', 'Fine & high winds'])).astype(int)\n",
    "#Road Conditions\n",
    "df['Dry_Road_ind'] = (df.Road_Surface_Conditions.isin (['Dry'])).astype(int)\n",
    "#Light Conditions\n",
    "df['Daylight_ind'] = (df.Light_Conditions.isin (['Daylight'])).astype(int)\n",
    "#Month\n",
    "df['Spring_ind'] = (df.Month.isin (['Feb', 'Mar', 'Apr'])).astype(int)  #used Irish definition for season\n",
    "df['Summer_ind'] = (df.Month.isin (['May', 'Jun', 'Jul'])).astype(int)  #used Irish definition for season\n",
    "df['Autumn_ind'] = (df.Month.isin (['May', 'Jun', 'Jul'])).astype(int)  #used Irish definition for season\n",
    "df['Winter_ind'] = (df.Month.isin (['Jan','Nov','Dec'])).astype(int)    #used Irish definition for season\n",
    "#Vehicle Type\n",
    "df['Veh_Car_ind'] = (df.Vehicle_Type.isin (['Car'])).astype(int)\n",
    "df['Veh_Motorcycle_ind'] = (df.Vehicle_Type.isin (['Motorcycle'])).astype(int)\n",
    "df['Veh_Van_ind'] = (df.Vehicle_Type.isin (['Van'])).astype(int)\n",
    "df['Veh_Truck_ind'] = (df.Vehicle_Type.isin (['Truck'])).astype(int)\n",
    "df['Veh_Bus_ind'] = (df.Vehicle_Type.isin (['Bus'])).astype(int)\n",
    "df['Veh_Agri_ind'] = (df.Vehicle_Type.isin (['Agri_vehicle'])).astype(int)\n",
    "df['Veh_Other_ind'] = (df.Vehicle_Type.isin (['Other'])).astype(int)\n",
    "\n",
    "#Road Type\n",
    "df['Rd_Dual_Crgwy_ind'] = (df.Road_Type.isin (['Dual carriageway'])).astype(int)\n",
    "df['Rd_Sngl_Crgwy_ind'] = (df.Road_Type.isin (['Single carriageway'])).astype(int)\n",
    "df['Rd_Rndabt_ind'] = (df.Road_Type.isin (['Roundabout'])).astype(int)\n",
    "df['Rd_One_Way_St_ind'] = (df.Road_Type.isin (['One way street'])).astype(int)\n",
    "df['Rd_Slip_Road_ind'] = (df.Road_Type.isin (['Slip road'])).astype(int)\n",
    "#Day of Week\n",
    "df['Monday_ind'] = (df.Day_of_Week.isin (['Monday'])).astype(int)\n",
    "df['Tuesday_ind'] = (df.Day_of_Week.isin (['Tuesday'])).astype(int)\n",
    "df['Wednesday_ind'] = (df.Day_of_Week.isin (['Wednesday'])).astype(int)\n",
    "df['Thursday_ind'] = (df.Day_of_Week.isin (['Thursday'])).astype(int)\n",
    "df['Friday_ind'] = (df.Day_of_Week.isin (['Friday'])).astype(int)\n",
    "df['Saturday_ind'] = (df.Day_of_Week.isin (['Saturday'])).astype(int)\n",
    "df['Sunday_ind'] = (df.Day_of_Week.isin (['Sunday'])).astype(int)\n",
    "\n",
    "#Point of impact\n",
    "df['POI_Nearside_ind'] = (df.Point_of_Impact.isin (['Nearside'])).astype(int)\n",
    "df['POI_Front_ind'] = (df.Point_of_Impact.isin (['Front'])).astype(int)\n",
    "df['POI_Back_ind'] = (df.Point_of_Impact.isin (['Back'])).astype(int)\n",
    "df['POI_Offside_ind'] = (df.Point_of_Impact.isin (['Offside'])).astype(int)\n",
    "df['POI_No_Impact_ind'] = (df.Point_of_Impact.isin (['Did not impact'])).astype(int)\n",
    "\n",
    "#Towing\n",
    "df['Towing_ind'] = (df.Towing_Ind.isin (['Y'])).astype(int)\n",
    "\n",
    "\n",
    "#Vehicle manouvre\n",
    "df['VM_Parked_ind'] = (df.Vehicle_Manoeuvre.isin (['Parked'])).astype(int)\n",
    "df['VM_Reversing_ind'] = (df.Vehicle_Manoeuvre.isin (['Reversing'])).astype(int)\n",
    "df['VM_Slowing_ind'] = (df.Vehicle_Manoeuvre.isin (['Slowing or stopping'])).astype(int)\n",
    "df['VM_Moving_off_ind'] = (df.Vehicle_Manoeuvre.isin (['Moving off'])).astype(int)\n",
    "df['VM_U_Turn_ind'] = (df.Vehicle_Manoeuvre.isin (['U-turn'])).astype(int)\n",
    "df['VM_Turning_Left_ind'] = (df.Vehicle_Manoeuvre.isin (['Turning left'])).astype(int)\n",
    "df['VM_Turning_Right_ind'] = (df.Vehicle_Manoeuvre.isin (['Turning right'])).astype(int)\n",
    "df['VM_Waiting_ind'] = (df.Vehicle_Manoeuvre.isin (['Waiting to turn right' ,'Waiting to go held up' ,'Waiting to turn left'])).astype(int)\n",
    "df['VM_Changing_lane_ind'] = (df.Vehicle_Manoeuvre.isin (['Changing lane to left' , 'Changing lane to right'])).astype(int)\n",
    "df['VM_Overtaking_ind'] = (df.Vehicle_Manoeuvre.isin (['Overtaking nearside' , 'Overtaking moving vehicle offside' , 'Overtaking static vehicle offside'])).astype(int)\n",
    "df['VM_Going_Ahead_ind'] = (df.Vehicle_Manoeuvre.isin (['Going ahead other','Going ahead left-hand bend', 'Going ahead right-hand bend'])).astype(int)\n",
    "\n",
    "#Skidding and Overturning\n",
    "df['Skidded_ind'] = (df.Skidding_and_Overturning.isin (['Skidded'])).astype(int)\n",
    "df['Jackknife_and_Overturn_ind'] = (df.Skidding_and_Overturning.isin (['Jackknifed and overturned'])).astype(int)\n",
    "df['Jackknifed_ind'] = (df.Skidding_and_Overturning.isin (['Jackknifed'])).astype(int)\n",
    "df['Overturned_ind'] = (df.Skidding_and_Overturning.isin (['Overturned'])).astype(int)\n",
    "df['Skid_and_Overturn_ind'] = (df.Skidding_and_Overturning.isin (['Skidded and overturned'])).astype(int)\n",
    "\n",
    "#Speed Limit\n",
    "df['SL_10_ind'] = (df.Speed_limit.isin (['10'])).astype(int)\n",
    "df['SL_20_ind'] = (df.Speed_limit.isin (['20'])).astype(int)\n",
    "df['SL_30_ind'] = (df.Speed_limit.isin (['30'])).astype(int)\n",
    "df['SL_40_ind'] = (df.Speed_limit.isin (['40'])).astype(int)\n",
    "df['SL_50_ind'] = (df.Speed_limit.isin (['50'])).astype(int)\n",
    "df['SL_60_ind'] = (df.Speed_limit.isin (['60'])).astype(int)\n",
    "df['SL_70_ind'] = (df.Speed_limit.isin (['70'])).astype(int)\n",
    "\n",
    "#Bin Driver Age\n",
    "df['Dr_Age_decile'] = (pd.qcut(df['Driver_Age'], 10, labels=False))+1\n",
    "\n",
    "df['Dr_Age_Up_to_25_ind'] = (df['Driver_Age'] <= 25 ).astype(int)\n",
    "df['Dr_Age_26_to_34_ind'] = ((df['Driver_Age'] > 25) & (df['Driver_Age'] <= 34)).astype(int)\n",
    "df['Dr_Age_35_to_44_ind'] = ((df['Driver_Age'] > 34) & (df['Driver_Age'] <= 44)).astype(int)\n",
    "df['Dr_Age_44_to_54_ind'] = ((df['Driver_Age'] > 44) & (df['Driver_Age'] <= 54)).astype(int)\n",
    "df['Dr_Age_55_plus_ind'] = ((df['Driver_Age'] > 54)).astype(int)\n",
    "\n",
    "#Bin Vehicle Age\n",
    "df['Veh_Age_decile'] = (pd.qcut(df['Vehicle_Age'], 10, labels=False))+1\n",
    "\n",
    "df['Veh_Age_0_to_3_ind'] = (df['Vehicle_Age'] <= 3 ).astype(int)\n",
    "df['Veh_Age_4_to_6_ind'] = ((df['Vehicle_Age'] > 3) & (df['Vehicle_Age'] <= 6)).astype(int)\n",
    "df['Veh_Age_7_to_9_ind'] = ((df['Vehicle_Age'] > 7) & (df['Vehicle_Age'] <= 9)).astype(int)\n",
    "df['Veh_Age_10_to_12_ind'] = ((df['Vehicle_Age'] > 9) & (df['Vehicle_Age'] <= 12)).astype(int)\n",
    "df['Veh_Age_13_plus_ind'] = ((df['Vehicle_Age'] > 12)).astype(int)\n",
    "\n",
    "#Bin Engine Capacity\n",
    "df['Eng_Cap_decile'] = (pd.qcut(df['Engine_Capacity'], 10, labels=False))+1\n",
    "\n",
    "df['Eng_Cap_0_to_1229_ind'] = (df['Engine_Capacity'] <= 1229 ).astype(int)\n",
    "df['Eng_Cap_1230_to_1497_ind'] = ((df['Engine_Capacity'] > 1229) & (df['Engine_Capacity'] <= 1497)).astype(int)\n",
    "df['Eng_Cap_1498_to_1794_ind'] = ((df['Engine_Capacity'] > 1497) & (df['Engine_Capacity'] <= 1794)).astype(int)\n",
    "df['Eng_Cap_1795_to_1997_ind'] = ((df['Engine_Capacity'] > 1794) & (df['Engine_Capacity'] <= 1997)).astype(int)\n",
    "df['Eng_Cap_1998_plus_ind'] = ((df['Engine_Capacity'] > 1997)).astype(int)\n",
    "\n",
    "\n",
    "#Age Gender Interactions\n",
    "df['Male_Dr_Age_Up_to_25_ind'] = ((df['Dr_Age_Up_to_25_ind'] == 1) & (df['Male_ind'] == 1)).astype(int)\n",
    "df['Male_Dr_Age_26_to_34_ind'] = ((df['Dr_Age_26_to_34_ind'] == 1) & (df['Male_ind'] == 1)).astype(int)\n",
    "df['Male_Dr_Age_35_to_44_ind'] = ((df['Dr_Age_35_to_44_ind'] == 1) & (df['Male_ind'] == 1)).astype(int)\n",
    "df['Male_Dr_Age_44_to_54_ind'] = ((df['Dr_Age_44_to_54_ind'] == 1) & (df['Male_ind'] == 1)).astype(int)\n",
    "df['Male_Dr_Age_55_plus_ind'] = ((df['Dr_Age_55_plus_ind'] == 1) & (df['Male_ind'] == 1)).astype(int)\n",
    "df['Female_Dr_Age_Up_to_25_ind'] = ((df['Dr_Age_Up_to_25_ind'] == 1) & (df['Male_ind'] == 0)).astype(int)\n",
    "df['Female_Dr_Age_26_to_34_ind'] = ((df['Dr_Age_26_to_34_ind'] == 1) & (df['Male_ind'] == 0)).astype(int)\n",
    "df['Female_Dr_Age_35_to_44_ind'] = ((df['Dr_Age_35_to_44_ind'] == 1) & (df['Male_ind'] == 0)).astype(int)\n",
    "df['Female_Dr_Age_44_to_54_ind'] = ((df['Dr_Age_44_to_54_ind'] == 1) & (df['Male_ind'] == 0)).astype(int)\n",
    "df['Female_Dr_Age_55_plus_ind'] = ((df['Dr_Age_55_plus_ind'] == 1) & (df['Male_ind'] == 0)).astype(int)\n",
    "\n",
    "\n",
    "#Time of day\n",
    "df['Mins_since_12_decile'] = (pd.qcut(df['Minutes_since_midnight'], 10, labels=False))+1\n",
    "\n",
    "#columns\n",
    "list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Eng_Cap_1998_plus_ind.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Categorical Columns and ID column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#update dataframe so as to remove redundant columns\n",
    "\n",
    "df = df[['Target_ind',\n",
    "         'Weekend_Ind',\n",
    "         #'ACC_VEH_ID',   #don't need this column unless you were scoring overall population and wanted to use to identify fraudster\n",
    "         'Male_ind',\n",
    "         'Urban_ind',\n",
    "         'Fine_Weather_ind',\n",
    "         'Dry_Road_ind',\n",
    "         'Daylight_ind',\n",
    "         'Spring_ind',\n",
    "         'Summer_ind',\n",
    "         'Autumn_ind',\n",
    "         'Winter_ind',\n",
    "         'Veh_Car_ind',\n",
    "         'Veh_Motorcycle_ind',\n",
    "         'Veh_Van_ind',\n",
    "         'Veh_Truck_ind',\n",
    "         'Veh_Bus_ind',\n",
    "         'Veh_Agri_ind',\n",
    "         'Veh_Other_ind',\n",
    "         'Rd_Dual_Crgwy_ind',\n",
    "         'Rd_Sngl_Crgwy_ind',\n",
    "         'Rd_Rndabt_ind',\n",
    "         'Rd_One_Way_St_ind',\n",
    "         'Rd_Slip_Road_ind',\n",
    "         'Monday_ind',\n",
    "         'Tuesday_ind',\n",
    "         'Wednesday_ind',\n",
    "         'Thursday_ind',\n",
    "         'Friday_ind',\n",
    "         'Saturday_ind',\n",
    "         'Sunday_ind',\n",
    "         'POI_Nearside_ind',\n",
    "         'POI_Front_ind',\n",
    "         'POI_Back_ind',\n",
    "         'POI_Offside_ind',\n",
    "         'POI_No_Impact_ind',\n",
    "         'Towing_ind',\n",
    "         'VM_Parked_ind',\n",
    "         'VM_Reversing_ind',\n",
    "         'VM_Slowing_ind',\n",
    "         'VM_Moving_off_ind',\n",
    "         'VM_U_Turn_ind',\n",
    "         'VM_Turning_Left_ind',\n",
    "         'VM_Turning_Right_ind',\n",
    "         'VM_Waiting_ind',\n",
    "         'VM_Changing_lane_ind',\n",
    "         'VM_Overtaking_ind',\n",
    "         'VM_Going_Ahead_ind',\n",
    "         'Skidded_ind',\n",
    "         'Jackknife_and_Overturn_ind',\n",
    "         'Jackknifed_ind',\n",
    "         'Overturned_ind',\n",
    "         'Skid_and_Overturn_ind',\n",
    "         \n",
    "         'Dr_Age_decile',\n",
    "         'Eng_Cap_decile',\n",
    "         'Veh_Age_decile',\n",
    "         'Mins_since_12_decile',\n",
    "         \n",
    "         'Dr_Age_Up_to_25_ind',\n",
    "         'Dr_Age_26_to_34_ind',\n",
    "         'Dr_Age_35_to_44_ind',\n",
    "         'Dr_Age_44_to_54_ind',\n",
    "         'Dr_Age_55_plus_ind',\n",
    "         'Veh_Age_0_to_3_ind',\n",
    "         'Veh_Age_4_to_6_ind',\n",
    "         'Veh_Age_7_to_9_ind',\n",
    "         'Veh_Age_10_to_12_ind',\n",
    "         'Veh_Age_13_plus_ind',\n",
    "         'Eng_Cap_0_to_1229_ind',\n",
    "         'Eng_Cap_1230_to_1497_ind',\n",
    "         'Eng_Cap_1498_to_1794_ind',\n",
    "         'Eng_Cap_1795_to_1997_ind',\n",
    "         'Eng_Cap_1998_plus_ind'  ,      \n",
    "        'SL_10_ind',\n",
    "        'SL_20_ind',\n",
    "        'SL_30_ind',\n",
    "        'SL_40_ind',\n",
    "        'SL_50_ind',\n",
    "        'SL_60_ind',\n",
    "        'SL_70_ind',\n",
    "        'Speed_Limit',\n",
    "        'Male_Dr_Age_Up_to_25_ind',\n",
    " 'Male_Dr_Age_26_to_34_ind',\n",
    " 'Male_Dr_Age_35_to_44_ind',\n",
    " 'Male_Dr_Age_44_to_54_ind',\n",
    " 'Male_Dr_Age_55_plus_ind',\n",
    " 'Female_Dr_Age_Up_to_25_ind',\n",
    " 'Female_Dr_Age_26_to_34_ind',\n",
    " 'Female_Dr_Age_35_to_44_ind',\n",
    " 'Female_Dr_Age_44_to_54_ind',\n",
    " 'Female_Dr_Age_55_plus_ind'\n",
    "           ]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests to ensure its copied correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df.head()\n",
    "#df.shape\n",
    "list(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that all columns are numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check which columns are numerics\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "newdf = df.select_dtypes(exclude=numerics)  #exclude numeric columns\n",
    "\n",
    "list(newdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create train and test sets\n",
    "train=df.sample(frac=0.7,random_state=200)  #random sample of 70% in train set\n",
    "test=df.drop(train.index)                   #remaining observations go into blind test set\n",
    "\n",
    "#Test the distributions are correct\n",
    "#len(train)\n",
    "#len(test)\n",
    "\n",
    "#Check percentage of target in each is roughly the same\n",
    "#train.Target_ind.sum()\n",
    "#test.Target_ind.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampling Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#undersample training set as target is rare event\n",
    "\n",
    "#Step1: create dataframe containing all training set with target_ind=1\n",
    "df4 = train.loc[df['Target_ind']==1]\n",
    "\n",
    "#Step2: create dataframe containing target_ind=0 but same number of observations as the numbr of observations where target_ind=1\n",
    "df5 = train.loc[df['Target_ind']==0]\n",
    "df5 = df5.sample(n=len(df4)  ,random_state=17) # replace  n=len(df4) with frac=.25 to undersample to a quarter\n",
    "\n",
    "#Step3: merge both into final training set dataframe\n",
    "final_train = pd.concat([df4, df5])\n",
    "len (final_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_cols = pd.DataFrame(columns=['Weekend_Ind',\n",
    " 'Male_ind',\n",
    " 'Urban_ind',\n",
    " 'Fine_Weather_ind',\n",
    " 'Dry_Road_ind',\n",
    " 'Daylight_ind',\n",
    "# 'Spring_ind',\n",
    "# 'Summer_ind',\n",
    "# 'Autumn_ind',\n",
    "# 'Winter_ind',\n",
    " 'Veh_Car_ind',\n",
    " 'Veh_Motorcycle_ind',\n",
    " 'Veh_Van_ind',\n",
    " 'Veh_Truck_ind',\n",
    " 'Veh_Bus_ind',\n",
    " 'Veh_Agri_ind',\n",
    " 'Veh_Other_ind',\n",
    " 'Rd_Dual_Crgwy_ind',\n",
    " 'Rd_Sngl_Crgwy_ind',\n",
    " 'Rd_Rndabt_ind',\n",
    " 'Rd_One_Way_St_ind',\n",
    " 'Rd_Slip_Road_ind',\n",
    "# 'Monday_ind',\n",
    "# 'Tuesday_ind',\n",
    "# 'Wednesday_ind',\n",
    "# 'Thursday_ind',\n",
    "# 'Friday_ind',\n",
    "# 'Saturday_ind',\n",
    "# 'Sunday_ind',\n",
    " 'POI_Nearside_ind',\n",
    " 'POI_Front_ind',\n",
    " 'POI_Back_ind',\n",
    " 'POI_Offside_ind',\n",
    " 'POI_No_Impact_ind',\n",
    " 'Towing_ind',\n",
    " 'VM_Parked_ind',\n",
    " 'VM_Reversing_ind',\n",
    " 'VM_Slowing_ind',\n",
    " 'VM_Moving_off_ind',\n",
    " 'VM_U_Turn_ind',\n",
    " 'VM_Turning_Left_ind',\n",
    " 'VM_Turning_Right_ind',\n",
    " 'VM_Waiting_ind',\n",
    " 'VM_Changing_lane_ind',\n",
    " 'VM_Overtaking_ind',\n",
    " 'VM_Going_Ahead_ind',\n",
    " 'Skidded_ind',\n",
    " 'Jackknife_and_Overturn_ind',\n",
    " 'Jackknifed_ind',\n",
    " 'Overturned_ind',\n",
    " 'Skid_and_Overturn_ind',\n",
    " 'Dr_Age_decile',\n",
    " 'Eng_Cap_decile',\n",
    " 'Veh_Age_decile',\n",
    " 'Mins_since_12_decile',\n",
    "# 'Dr_Age_Up_to_25_ind',\n",
    "# 'Dr_Age_26_to_34_ind',\n",
    "# 'Dr_Age_35_to_44_ind',\n",
    "# 'Dr_Age_44_to_54_ind',\n",
    "# 'Dr_Age_55_plus_ind',\n",
    "# 'Veh_Age_0_to_3_ind',\n",
    "# 'Veh_Age_4_to_6_ind',\n",
    "# 'Veh_Age_7_to_9_ind',\n",
    "# 'Veh_Age_10_to_12_ind',\n",
    "# 'Veh_Age_13_plus_ind',\n",
    "# 'Eng_Cap_0_to_1229_ind',\n",
    "# 'Eng_Cap_1230_to_1497_ind',\n",
    "# 'Eng_Cap_1498_to_1794_ind',\n",
    "# 'Eng_Cap_1795_to_1997_ind',\n",
    "# 'Eng_Cap_1998_plus_ind',                                \n",
    "# 'SL_10_ind',\n",
    "# 'SL_20_ind',\n",
    "# 'SL_30_ind',\n",
    "# 'SL_40_ind',\n",
    "# 'SL_50_ind',\n",
    "# 'SL_60_ind',\n",
    "# 'SL_70_ind',                                     \n",
    " 'Speed_Limit'\n",
    "# 'Male_Dr_Age_Up_to_25_ind',\n",
    "# 'Male_Dr_Age_26_to_34_ind',\n",
    "# 'Male_Dr_Age_35_to_44_ind',\n",
    "# 'Male_Dr_Age_44_to_54_ind',\n",
    "# 'Male_Dr_Age_55_plus_ind',\n",
    "# 'Female_Dr_Age_Up_to_25_ind',\n",
    "# 'Female_Dr_Age_26_to_34_ind',\n",
    "# 'Female_Dr_Age_35_to_44_ind',\n",
    "# 'Female_Dr_Age_44_to_54_ind',\n",
    "# 'Female_Dr_Age_55_plus_ind'\n",
    "                                 ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Test splits and sklearn imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import useful functions from sklearn\n",
    "from sklearn.cross_validation import train_test_split #didn't use because it doesn't accommodate undersampling\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn import linear_model as lm \n",
    "from sklearn.tree import DecisionTreeClassifier as dt\n",
    "from sklearn import svm \n",
    "from patsy import dmatrices\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import calibration\n",
    "\n",
    "#create data_train array\n",
    "data_train = final_train.as_matrix(columns=[ list(data_cols) ])\n",
    "#create target_train array\n",
    "target_train = final_train.as_matrix(columns=['Target_ind'])\n",
    "\n",
    "# flatten y into a 1-D array\n",
    "target_train = np.ravel(target_train)\n",
    "\n",
    "#create data_test array\n",
    "data_test = test.as_matrix(columns=[ list(data_cols) ])\n",
    "#create target_test array\n",
    "target_test = test.as_matrix(columns=['Target_ind'])\n",
    "# flatten y into a 1-D array\n",
    "target_test = np.ravel(target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what percentage of base had serious accident?\n",
    "check = ((target_test.mean()))\n",
    "print(check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Recursive Feature Elimination\n",
    "model_RFE_lr = lm.LogisticRegression()\n",
    "\n",
    "# create the RFE model\n",
    "rfe_lr = RFE(model_RFE_lr, n_features_to_select=20)\n",
    "rfe_lr = rfe_lr.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination Cross Validated: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Recursive Feature Elimination\n",
    "model_RFE_lr = lm.LogisticRegression()\n",
    "\n",
    "# create the RFECV model\n",
    "rfe_lr = RFECV(model_RFE_lr, step=1, cv=10, scoring='accuracy')   #'roc_auc' \n",
    "rfe_lr = rfe_lr.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table of Columns to keep: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lr = rfe_lr.support_\n",
    "rank_lr = rfe_lr.ranking_\n",
    "\n",
    "RFE_cols_lr = pd.DataFrame(result_lr, columns = ['Keep'])\n",
    "RFE_rank_lr = pd.DataFrame(rank_lr, columns = ['Rank'])\n",
    "data_cols_df = pd.DataFrame(list(data_cols), columns =['Variable'])\n",
    "\n",
    "\n",
    "RFE_cols_lr['indexs'] = RFE_cols_lr.index\n",
    "RFE_rank_lr['indexs'] = RFE_rank_lr.index\n",
    "data_cols_df['indexs'] = data_cols_df.index\n",
    "\n",
    "keep_vars_lr = pd.merge(data_cols_df, RFE_cols_lr , on=['indexs'])\n",
    "keep_vars_lr = pd.merge(keep_vars_lr, RFE_rank_lr , on=['indexs'])\n",
    "keep_vars_lr = keep_vars_lr.drop('indexs', axis=1)\n",
    "\n",
    "pd.options.display.max_rows = 90\n",
    "keep_vars_lr[:100] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation:  Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Columns: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_cols_lr = pd.DataFrame(columns=['Weekend_Ind'\n",
    ",'Male_ind'\n",
    ",'Urban_ind'\n",
    ",'Fine_Weather_ind'\n",
    ",'Dry_Road_ind'\n",
    ",'Daylight_ind'\n",
    ",'Veh_Car_ind'\n",
    ",'Veh_Motorcycle_ind'\n",
    ",'Veh_Van_ind'\n",
    ",'Veh_Truck_ind'\n",
    ",'Veh_Bus_ind'\n",
    ",'Veh_Agri_ind'\n",
    ",'Rd_Dual_Crgwy_ind'\n",
    ",'Rd_Sngl_Crgwy_ind'\n",
    ",'Rd_Rndabt_ind'\n",
    ",'Rd_One_Way_St_ind'\n",
    ",'Rd_Slip_Road_ind'\n",
    ",'POI_Nearside_ind'\n",
    ",'POI_Front_ind'\n",
    ",'POI_Back_ind'\n",
    ",'POI_Offside_ind'\n",
    ",'POI_No_Impact_ind'\n",
    ",'Towing_ind'\n",
    ",'VM_Parked_ind'\n",
    ",'VM_Reversing_ind'\n",
    ",'VM_Slowing_ind'\n",
    ",'VM_Moving_off_ind'\n",
    ",'VM_U_Turn_ind'\n",
    ",'VM_Turning_Left_ind'\n",
    ",'VM_Turning_Right_ind'\n",
    ",'VM_Waiting_ind'\n",
    ",'VM_Changing_lane_ind'\n",
    ",'VM_Overtaking_ind'\n",
    ",'VM_Going_Ahead_ind'\n",
    ",'Skidded_ind'\n",
    ",'Jackknife_and_Overturn_ind'\n",
    ",'Jackknifed_ind'\n",
    ",'Overturned_ind'\n",
    ",'Skid_and_Overturn_ind'\n",
    ",'Dr_Age_decile'\n",
    ",'Veh_Age_decile'\n",
    ",'Speed_Limit'\n",
    " ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Train and Test sets: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train_lr = final_train.as_matrix(columns=[ list(final_cols_lr) ])\n",
    "data_test_lr = test.as_matrix(columns=[ list(final_cols_lr) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Build: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = lm.LogisticRegression()\n",
    "model_lr.fit(data_train_lr, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coefficients: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the coefficients\n",
    "coef = pd.DataFrame(list(zip(final_cols_lr, np.transpose(model_lr.coef_))),columns= ['Variable','Coefficient'])\n",
    "\n",
    "coef.sort_values('Coefficient',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on Blind Test: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predict target for the test set\n",
    "pred_model_lr = model_lr.predict(data_test_lr)\n",
    "\n",
    "#generate class probabilities\n",
    "pred_probs_model_lr = model_lr.predict_proba(data_test_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection: Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination Cross Validated: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Recursive Feature Elimination\n",
    "model_RFE_dt = dt(criterion='entropy' , max_depth = 10)\n",
    "\n",
    "# create the RFE model\n",
    "#rfe_dt = RFE(model_RFE_dt, n_features_to_select=10, step=1 )\n",
    "rfe_dt = RFECV(model_RFE_dt, step=1, cv=10, scoring='accuracy')   #'roc_auc' \n",
    "rfe_dt = rfe_dt.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table of Columns to keep: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dt = rfe_dt.support_\n",
    "rank_dt = rfe_dt.ranking_\n",
    "\n",
    "RFE_cols_dt = pd.DataFrame(result_dt, columns = ['Keep'])\n",
    "RFE_rank_dt = pd.DataFrame(rank_dt, columns = ['Rank'])\n",
    "data_cols_df = pd.DataFrame(list(data_cols), columns =['Variable'])\n",
    "\n",
    "\n",
    "RFE_cols_dt['indexs'] = RFE_cols_dt.index\n",
    "RFE_rank_dt['indexs'] = RFE_rank_dt.index\n",
    "data_cols_df['indexs'] = data_cols_df.index\n",
    "\n",
    "keep_vars_dt = pd.merge(data_cols_df, RFE_cols_dt , on=['indexs'])\n",
    "keep_vars_dt = pd.merge(keep_vars_dt, RFE_rank_dt , on=['indexs'])\n",
    "keep_vars_dt = keep_vars_dt.drop('indexs', axis=1)\n",
    "\n",
    "pd.options.display.max_rows = 90\n",
    "keep_vars_dt[:100] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation: Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Columns: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_cols_dt = pd.DataFrame(columns=[\n",
    "'Weekend_Ind'\n",
    ",'Male_ind'\n",
    ",'Urban_ind'\n",
    ",'Fine_Weather_ind'\n",
    ",'Dry_Road_ind'\n",
    ",'Daylight_ind'\n",
    ",'Veh_Car_ind'\n",
    ",'Veh_Motorcycle_ind'\n",
    ",'Veh_Van_ind'\n",
    ",'Veh_Truck_ind'\n",
    ",'Rd_Dual_Crgwy_ind'\n",
    ",'Rd_Sngl_Crgwy_ind'\n",
    ",'Rd_Rndabt_ind'\n",
    ",'POI_Nearside_ind'\n",
    ",'POI_Front_ind'\n",
    ",'POI_Back_ind'\n",
    ",'POI_Offside_ind'\n",
    ",'POI_No_Impact_ind'\n",
    ",'Towing_ind'\n",
    ",'VM_Parked_ind'\n",
    ",'VM_Reversing_ind'\n",
    ",'VM_Slowing_ind'\n",
    ",'VM_Moving_off_ind'\n",
    ",'VM_U_Turn_ind'\n",
    ",'VM_Turning_Left_ind'\n",
    ",'VM_Turning_Right_ind'\n",
    ",'VM_Waiting_ind'\n",
    ",'VM_Changing_lane_ind'\n",
    ",'VM_Overtaking_ind'\n",
    ",'VM_Going_Ahead_ind'\n",
    ",'Skidded_ind'\n",
    ",'Overturned_ind'\n",
    ",'Skid_and_Overturn_ind'\n",
    ",'Dr_Age_decile'\n",
    ",'Eng_Cap_decile'\n",
    ",'Veh_Age_decile'\n",
    ",'Mins_since_12_decile'\n",
    ",'Speed_Limit'  \n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Train and Test sets: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train_dt = final_train.as_matrix(columns=[ list(final_cols_dt) ])\n",
    "data_test_dt = test.as_matrix(columns=[ list(final_cols_dt) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Build: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt = dt(criterion='entropy' , max_depth = 10)\n",
    "model_dt.fit(data_train_dt, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on Blind Test: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predict target for the test set\n",
    "pred_model_dt = model_dt.predict(data_test_dt)\n",
    "\n",
    "#generate class probabilities\n",
    "pred_probs_model_dt = model_dt.predict_proba(data_test_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection: SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination Cross Validated: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Recursive Feature Elimination\n",
    "#model_RFE_svm = svm.SVC(kernel='linear', C=1.0)\n",
    "model_RFE_svm = svm.LinearSVC(C=100, loss='hinge', max_iter=5000 )\n",
    "\n",
    "# create the RFE model\n",
    "#rfe_svm = RFE(model_RFE_svm, n_features_to_select=8, step=1 )\n",
    "rfe_svm = RFECV(model_RFE_svm, step=1, cv=10, scoring='accuracy')   #roc_auc can't be used for svm as it does not provide probabilities\n",
    "rfe_svm = rfe_svm.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table of Columns to keep: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_svm = rfe_svm.support_\n",
    "rank_svm = rfe_svm.ranking_\n",
    "\n",
    "RFE_cols_svm = pd.DataFrame(result_svm, columns = ['Keep'])\n",
    "RFE_rank_svm = pd.DataFrame(rank_svm, columns = ['Rank'])\n",
    "data_cols_df = pd.DataFrame(list(data_cols), columns =['Variable'])\n",
    "\n",
    "\n",
    "RFE_cols_svm['indexs'] = RFE_cols_svm.index\n",
    "RFE_rank_svm['indexs'] = RFE_rank_svm.index\n",
    "data_cols_df['indexs'] = data_cols_df.index\n",
    "\n",
    "keep_vars_svm = pd.merge(data_cols_df, RFE_cols_svm , on=['indexs'])\n",
    "keep_vars_svm = pd.merge(keep_vars_svm, RFE_rank_svm , on=['indexs'])\n",
    "keep_vars_svm = keep_vars_svm.drop('indexs', axis=1)\n",
    "\n",
    "pd.options.display.max_rows = 90\n",
    "keep_vars_svm[:100] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation: SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Columns: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_cols_svm = pd.DataFrame(columns=['Urban_ind',\n",
    "'Veh_Motorcycle_ind',\n",
    "'Veh_Van_ind',\n",
    "'Rd_Rndabt_ind',\n",
    "'Rd_Slip_Road_ind',\n",
    "'POI_Back_ind',\n",
    "'VM_Parked_ind',\n",
    "'VM_Reversing_ind',\n",
    "'VM_Slowing_ind',\n",
    "'VM_U_Turn_ind',\n",
    "'VM_Turning_Right_ind',\n",
    "'VM_Overtaking_ind',\n",
    "'VM_Going_Ahead_ind',\n",
    "'Jackknife_and_Overturn_ind',\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Train and Test sets: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train_svm = final_train.as_matrix(columns=[ list(final_cols_svm) ])\n",
    "data_test_svm = test.as_matrix(columns=[ list(final_cols_svm) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Build: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_svm = svm.SVC(kernel='linear',max_iter=5000)\n",
    "model_svm = svm.LinearSVC(loss='hinge', max_iter=5000 ) #runs faster than using above model build\n",
    "\n",
    "model_svm = calibration.CalibratedClassifierCV(model_svm) \n",
    "model_svm.fit(data_train_svm, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on Blind Test: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predict target for the test set\n",
    "pred_model_svm = model_svm.predict(data_test_svm)\n",
    "\n",
    "#generate class probabilities\n",
    "pred_probs_model_svm = model_svm.predict_proba(data_test_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Performance of the model on the Blind Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('LR - Train Accuracy:     %f'%model_lr.score(data_train_lr, target_train))\n",
    "print('LR - Test Accuracy:      %f'%model_lr.score(data_test_lr, target_test))\n",
    "\n",
    "print('DT - Train Accuracy:     %f'%model_dt.score(data_train_dt, target_train))\n",
    "print('DT - Test Accuracy:      %f'%model_dt.score(data_test_dt, target_test))\n",
    "\n",
    "print('SVM - Train Accuracy:     %f'%model_svm.score(data_train_svm, target_train))\n",
    "print('SVM - Test Accuracy:      %f'%model_svm.score(data_test_svm, target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Accuracy:    LR - %f'%metrics.accuracy_score(target_test, pred_model_lr), ' DT - %f'%metrics.accuracy_score(target_test, pred_model_dt) , ' SVM - %f'%metrics.accuracy_score(target_test, pred_model_svm))\n",
    "print ('ROC AUC:     LR - %f'%metrics.roc_auc_score(target_test, pred_probs_model_lr[:, 1]),' DT - %f'%metrics.roc_auc_score(target_test, pred_probs_model_dt[:, 1]),' SVM - %f'%metrics.roc_auc_score(target_test, pred_probs_model_svm[:, 1]))\n",
    "print ('Gini:        LR - %f'%(2*(metrics.roc_auc_score(target_test, pred_probs_model_lr[:, 1])) - 1) , ' DT - %f'%(2*(metrics.roc_auc_score(target_test, pred_probs_model_dt[:, 1])) - 1),' SVM - %f'%(2*(metrics.roc_auc_score(target_test, pred_probs_model_svm[:, 1])) - 1) )  \n",
    "print ('Recall:      LR - %f'%metrics.recall_score(target_test,pred_model_lr), ' DT - %f'%metrics.recall_score(target_test,pred_model_dt) , ' SVM - %f'%metrics.recall_score(target_test,pred_model_svm))\n",
    "print ('Precision:   LR - %f'%metrics.precision_score(target_test,pred_model_lr) , ' DT - %f'%metrics.precision_score(target_test,pred_model_dt) ,  ' SVM - %f'%metrics.precision_score(target_test,pred_model_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#generate class probabilities for target ind = 1\n",
    "pred_probs_target_lr = model_lr.predict_proba(data_test_lr)[:, 1]\n",
    "pred_probs_target_dt = model_dt.predict_proba(data_test_dt)[:, 1]\n",
    "pred_probs_target_svm = model_svm.predict_proba(data_test_svm)[:, 1]\n",
    "\n",
    "fpr_lr, tpr_lr, thresholds_lr = metrics.roc_curve(target_test , pred_probs_target_lr)\n",
    "fpr_dt, tpr_dt, thresholds_dt = metrics.roc_curve(target_test , pred_probs_target_dt)\n",
    "fpr_svm, tpr_svm, thresholds_svm = metrics.roc_curve(target_test , pred_probs_target_svm)\n",
    "\n",
    "#line to show Logistic Regression\n",
    "plt.plot(fpr_lr, tpr_lr, linewidth= 1.5, color = 'c', label='Logistic Regression')\n",
    "\n",
    "#line to show Decision Tree\n",
    "plt.plot(fpr_dt, tpr_dt, linewidth= 1.5, color = 'm', label='Decision Tree')\n",
    "\n",
    "#line to show Support Vector Machine\n",
    "plt.plot(fpr_svm, tpr_svm, linewidth= 1.5, color = 'y', label='Support Vector Machine')\n",
    "\n",
    "#line to show the the diagonal\n",
    "plt.plot(fpr_lr, fpr_lr, linewidth= 1.5, color = '0.5')\n",
    "\n",
    "#plot details\n",
    "plt.legend(bbox_to_anchor=(1.02, 1), loc=2, borderaxespad=0. , fontsize=10)\n",
    "plt.xlim(-0.02 , 1.02)\n",
    "plt.ylim(-0.02 , 1.02)\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('False Positive Rate (100 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_lr, fp_lr, fn_lr, tp_lr = confusion_matrix(target_test, pred_model_lr).ravel()\n",
    "print('Logistic Regression Model')\n",
    "print('TN: %d'%tn_lr, 'FP: %d'%fp_lr, 'FN: %d'%fn_lr, 'TP: %d'%tp_lr)\n",
    "print (metrics.classification_report(target_test, pred_model_lr))\n",
    "\n",
    "\n",
    "tn_dt, fp_dt, fn_dt, tp_dt = confusion_matrix(target_test, pred_model_dt).ravel()\n",
    "print('Decision Tree Model')\n",
    "print('TN: %d'%tn_dt, 'FP: %d'%fp_dt, 'FN: %d'%fn_dt, 'TP: %d'%tp_dt)\n",
    "print (metrics.classification_report(target_test, pred_model_dt))\n",
    "\n",
    "tn_svm, fp_svm, fn_svm, tp_svm = confusion_matrix(target_test, pred_model_svm).ravel()\n",
    "print('SVM Model')\n",
    "print('TN: %d'%tn_svm, 'FP: %d'%fp_svm, 'FN: %d'%fn_svm, 'TP: %d'%tp_svm)\n",
    "print (metrics.classification_report(target_test, pred_model_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulatative Lift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Cumulative Lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(pred_probs_target_lr, columns=['probs'])\n",
    "df3 = pd.DataFrame(target_test, columns=['actual'])\n",
    "\n",
    "df2 = df3.join(df2,  how='outer')\n",
    "\n",
    "#df2 = df2.sort(columns = 'probs')\n",
    "df2['index1'] = df2.index\n",
    "df2['decile_probs'] = (pd.qcut(df2['probs'], 10, labels=False))+1\n",
    "\n",
    "#deciles by probs of actual ind\n",
    "probs_act = (df2.groupby('decile_probs')['actual'].sum())\n",
    "#counts by decile\n",
    "dist_pop = (df2.groupby('decile_probs')['actual'].count())\n",
    "\n",
    "print(probs_act, dist_pop)\n",
    "df2.groupby('decile_probs').mean()\n",
    "\n",
    "#the rest is done in excel i.e. divide decile_probs by counts to work out cum_lift per decile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Cumulative Lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame(pred_probs_target_dt, columns=['probs'])\n",
    "df5 = pd.DataFrame(target_test, columns=['actual'])\n",
    "\n",
    "df4 = df5.join(df4,  how='outer')\n",
    "\n",
    "#different method needed for deciles because of non unique bin edges\n",
    "df4['decile_probs'] = (pd.qcut(df4.probs.rank(method='first'), 10, labels=False))+1\n",
    "\n",
    "\n",
    "#deciles by probs of actual ind\n",
    "probs_act_dt = (df4.groupby('decile_probs')['actual'].sum())\n",
    "#counts by decile\n",
    "dist_pop_dt = (df4.groupby('decile_probs')['actual'].count())\n",
    "\n",
    "print(probs_act_dt , dist_pop_dt)\n",
    "df4.groupby('decile_probs').mean()\n",
    "\n",
    "#the rest is done in excel i.e. divide decile_probs by counts to work out cum_lift per decile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine Cumulative Lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = pd.DataFrame(pred_probs_target_svm, columns=['probs'])\n",
    "df7 = pd.DataFrame(target_test, columns=['actual'])\n",
    "\n",
    "df6 = df7.join(df6,  how='outer')\n",
    "\n",
    "#different method needed for deciles because of non unique bin edges\n",
    "df6['decile_probs'] = (pd.qcut(df6.probs.rank(method='first'), 10, labels=False))+1\n",
    "\n",
    "\n",
    "#deciles by probs of actual ind\n",
    "probs_act_svm = (df6.groupby('decile_probs')['actual'].sum())\n",
    "#counts by decile\n",
    "dist_pop_svm = (df6.groupby('decile_probs')['actual'].count())\n",
    "\n",
    "print(probs_act_svm , dist_pop_svm)\n",
    "df6.groupby('decile_probs').mean()\n",
    "\n",
    "#the rest is done in excel i.e. divide decile_probs by counts to work out cum_lift per decile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting Thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pred_probs_target_lr, bins=10, color = 'c')\n",
    "plt.xlim(0,1)\n",
    "plt.xlabel('Predicted probabilities of Serious accident')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pred_probs_target_dt, bins=10, color = 'm')\n",
    "plt.xlim(0,1)\n",
    "plt.xlabel('Predicted probabilities of Serious accident')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Decision Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.hist(pred_probs_target_svm, bins=10, color = 'y')\n",
    "plt.xlim(0,1)\n",
    "plt.xlabel('Predicted probabilities of Serious accident')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SVM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying Different Probability Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust threshold for predcted probability\n",
    "from sklearn.preprocessing import binarize\n",
    "target_pred_class_lr = binarize(pred_probs_target_lr, 0.47)[0]\n",
    "target_pred_class_dt = binarize(pred_probs_target_dt, 0.45)[0]\n",
    "target_pred_class_svm = binarize(pred_probs_target_svm, 0.47)[0]\n",
    "\n",
    "print (metrics.classification_report(target_test, target_pred_class_lr))\n",
    "print (metrics.classification_report(target_test, target_pred_class_dt))\n",
    "print (metrics.classification_report(target_test, target_pred_class_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
